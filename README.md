### Hi there 👋

I am a PhD Student in [Health Data Science at Oxford](https://www.bdi.ox.ac.uk/study/cdt)
supervised by [Professor Jens Rittscher](https://dartlunghealth.co.uk/team/prof-jens-rittscher/), [Dr Tapabrata (Rohan) Chakraborty](https://dartlunghealth.co.uk/team/dr-tapabrata-rohan-chakraborty/), and funded by [Professor Fergus Gleeson](https://www.oncology.ox.ac.uk/team/fergus-gleeson).
I am focusing on applications of **Computer Vision** 👀💻 to improving diagnostics and treatment of patients with lung cancer as part of the [DART](https://dartlunghealth.co.uk/) lung health project (see [my role](https://dartlunghealth.co.uk/team/george-batchkala/) in the project).

Recently I was working on reproducing a CVPR'21 work called "Multiple Instance Captioning: Learning Representations From Histopathology Textbooks and Articles" ([CVPR'21 link](https://openaccess.thecvf.com/content/CVPR2021/html/Gamper_Multiple_Instance_Captioning_Learning_Representations_From_Histopathology_Textbooks_and_Articles_CVPR_2021_paper.html)). I found the work interesting and I wan to use the pre-trained visual backbone in my future research. It uses the methods described in another CVPR'21 work "VirTex: Learning Visual Representations from Textual Annotations" ([CVPR'21 link](https://openaccess.thecvf.com/content/CVPR2021/html/Desai_VirTex_Learning_Visual_Representations_From_Textual_Annotations_CVPR_2021_paper.html)) to train a ResNet visual 👀 encoder and a transformer textual 💬 decoder on the new [ARCH dataset](https://warwick.ac.uk/fac/cross_fac/tia/data/arch). You can see my work here: [GeorgeBatch/arch-pre-training](https://github.com/GeorgeBatch/arch-pre-training).

If you also want to start working with Histopathology images, but do not have or are waiting for your own data, have a look at the "The Cancer Genome Atlas" ([TCGA](https://portal.gdc.cancer.gov/)) web page. I recently got some experience with downloading diagnostic slides of lung cancer images from there. First I tried [using Google Drive](https://github.com/GeorgeBatch/TCGA-lung-download-GD) and then succeeded using [TCGA official client](https://github.com/GeorgeBatch/TCGA_lung). Another thing you can do if you are lacking medical data is to simulate parts of your future workflow on natural images, e.g. classifying medical images for presence or absence of particular patterns can be similar to classifying natural images for presence or absence of particular objects. I used images from the [COCO dataset](https://cocodataset.org/#home). You can see my work here: [GeorgeBatch/cocoapi](https://github.com/GeorgeBatch/cocoapi).

- 🎓 Previously, I studied [Mathematics and Statistics at Warwick](https://warwick.ac.uk/study/undergraduate/courses/mathsstatsbsc) for my Bachelors and did my [Masters in Statistics at Oxford](http://www.stats.ox.ac.uk/study-here/taught-postgraduate/msc-in-statistical-science/).
- 🌱 Separately from my PhD program, I’m currently learning cool **NLP** 💬💻 techniques ([repository](https://github.com/GeorgeBatch/nlp_from_dls)) taught by the [Deep Learning School](https://www.dlschool.org/advanced-track) from [MIPT](https://mipt.ru/english/). The course is only taught in Russian 🇷🇺.
- 🚀 I also found the YouTube playlist on [Structuring Machine Learning Projects](https://www.youtube.com/playlist?list=PLkDaE6sCZn6E7jZ9sN_xHwSHOdjUxUW_b) (Course 3 of the Deep Learning Specialization on Coursera) extremely useful. I started watching the videos to answer some of the questions related to the multilabel classification project I was working on at the time ([GeorgeBatch/cocoapi](https://github.com/GeorgeBatch/cocoapi)). I liked the explanations and Andrew Ng's delivery style so much that I enrolled and [completed](https://www.coursera.org/account/accomplishments/specialization/4HEL4XDPPGPF) the [Deep Learning Specialization](https://www.coursera.org/specializations/deep-learning).

----

Here are some of the best free online resources to boost your ML/DL knowledge 🚀 I am currently doing it, while skipping the repetitive parts ⏰

- English 🇬🇧
  - [Deep Learning](https://atcold.github.io/pytorch-Deep-Learning/) from [NYU](https://www.nyu.edu/admissions.html) by [Yann LeCun](https://twitter.com/ylecun) and [Alfredo Canziani](https://twitter.com/alfcnz) (next on my list ⏭️)
  - [CS231n: Convolutional Neural Networks for Visual Recognition](http://cs231n.stanford.edu/) from [Stanford](https://www.stanford.edu)
  - [CS224n: Natural Language Processing with Deep Learning](http://web.stanford.edu/class/cs224n/) from [Stanford](https://www.stanford.edu)

- Russian 🇷🇺
    - [Deep Learning (part 1)](https://stepik.org/course/91157/syllabus) similar to CS231n ✅ - [repository](https://github.com/GeorgeBatch/cv_from_dls) 👀 
    - [Deep Learning (part 2)](https://stepik.org/course/92488/syllabus) similar to CS224n ⏳ - [repository](https://github.com/GeorgeBatch/nlp_from_dls) 💬 

----

- 📫 How to reach me
  - LinkedIn: [george-batchkala](https://www.linkedin.com/in/george-batchkala/) 🔗
  - My page on DART: [george-batchkala](https://dartlunghealth.co.uk/team/george-batchkala/) 🔗
  - GitHub: [GeorgeBatch](https://github.com/GeorgeBatch) 🔗
  - Kaggle: [George Batchkala](https://www.kaggle.com/gbatchkala) 🔗

<!--
**GeorgeBatch/GeorgeBatch** is a ✨ _special_ ✨ repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- 🔭 I’m currently working on ...
- 🌱 I’m currently learning ...
- 👯 I’m looking to collaborate on ...
- 🤔 I’m looking for help with ...
- 💬 Ask me about ...
- 📫 How to reach me: ...
- 😄 Pronouns: ...
- ⚡ Fun fact: ...
-->
